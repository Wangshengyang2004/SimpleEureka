```python
def calculate_metrics(self) -> None:
    # Calculate the distance between the drone and the target
    target_dist = torch.norm(self.root_pos - self.target_positions, dim=1)
    
    # Reward for being close to the target
    pos_reward = torch.exp(-3 * target_dist)
    
    # Reward for drone's orientation
    norm_quat = torch.norm(self.root_rot, dim=1, keepdim=True)
    quat_normalized = self.root_rot / norm_quat
    dot_product = torch.sum(quat_normalized[:, [1, 2, 3]] * self.target_orientation, dim=1)
    orient_reward = torch.exp(-5 * (1 - abs(dot_product)))
    
    # Reward for drone's speed along the trajectory
    linear_vel = torch.norm(self.root_velocities[:, :3], dim=1)
    speed_reward = torch.exp(-5 * (abs(linear_vel - self.desired_speed) / self.desired_speed))
    
    # Reward for drone's angular velocity for spinning
    angular_vel = torch.norm(self.root_velocities[:, 3:], dim=1)
    spin_reward = torch.exp(-3 * (abs(angular_vel - self.desired_angular_vel) / self.desired_angular_vel))
    
    # Combine all rewards
    self.rew_buf = pos_reward + orient_reward + speed_reward + spin_reward
    
    # Log individual reward components
    self.episode_sums["rew_pos"] += pos_reward
    self.episode_sums["rew_orient"] += orient_reward
    self.episode_sums["rew_speed"] += speed_reward
    self.episode_sums["rew_spin"] += spin_reward
    
    # Log raw information
    self.episode_sums["raw_dist"] += target_dist
    self.episode_sums["raw_orient"] += dot_product
    self.episode_sums["raw_speed"] += linear_vel
    self.episode_sums["raw_spin"] += angular_vel

def is_done(self) -> None:
    # Termination conditions based on distance, orientation, and episode length
    die = torch.zeros_like(self.reset_buf)
    
    # Too far from target or not oriented correctly
    die = torch.where(self.target_dist > 10.0, torch.ones_like(self.reset_buf), die)
    die = torch.where(abs(dot_product) < 0.5, torch.ones_like(self.reset_buf), die)
    
    # Episode length limit reached
    self.reset_buf = torch.where(self.progress_buf >= self._max_episode_length - 1, torch.ones_like(self.reset_buf), die)
    
    # Update done flags
    self.done = die.bool()

#END
```