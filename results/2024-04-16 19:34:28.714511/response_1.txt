```python
def calculate_metrics(self) -> None:
    # Calculate the distance between the quadcopter and the target
    target_dist = torch.norm(self.root_pos - self.target_positions, dim=1)
    
    # Reward for being close to the target
    pos_reward = torch.exp(-3 * target_dist)
    
    # Reward for maintaining the correct orientation
    ups = quat_axis(self.root_rot, 2)
    up_reward = torch.exp(-3 * (1 - ups[..., 2].item()))

    # Reward for maintaining the correct speed
    desired_speed = 2 * math.pi / 3.5  # example speed
    current_speeds = torch.norm(self.root_velocities[:, :3], dim=1)
    speed_diff = torch.abs(current_speeds - desired_speed)
    speed_reward = torch.exp(-3 * speed_diff)

    # Reward for maintaining the correct trajectory
    traj = self.next_step - self.scaled_points
    norm_root_vel = self.root_velocities[:, :3] / torch.norm(self.root_velocities[:, :3], dim=1, keepdim=True)
    norm_traj = traj / torch.norm(traj, dim=1, keepdim=True)
    dot_product = torch.sum(norm_root_vel * norm_traj, dim=1)
    colinearity = 1 - dot_product
    coline_reward = torch.exp(-3 * colinearity)

    # Reward for spinning in the Y-axis
    y_angvel = self.root_velocities[:, 3]  # Y-axis angular velocity for spinning
    desired_y_angvel = 2 * math.pi / 3.5  # Desired spin rate around Y-axis
    y_angvel_diff = y_angvel - desired_y_angvel
    y_penalty = torch.square(y_angvel_diff).sum(-1)
    spin_reward = torch.exp(-1 * y_penalty)

    # Combined reward
    self.rew_buf[:] = (pos_reward + speed_reward + coline_reward) * (1 + up_reward + spin_reward)

    # Log individual reward components
    self.episode_sums["rew_pos"] += pos_reward
    self.episode_sums["rew_orient"] += up_reward
    self.episode_sums["rew_speed"] += speed_reward
    self.episode_sums["rew_coline"] += coline_reward
    self.episode_sums["rew_spin"] += spin_reward

    # Log raw information
    self.episode_sums["raw_dist"] += target_dist
    self.episode_sums["raw_orient"] += ups[..., 2]

def is_done(self) -> None:
    # Reset due to misbehavior (e.g., distance from target > 10)
    die = torch.where(self.target_dist > 10.0, torch.ones_like(self.reset_buf), torch.zeros_like(self.reset_buf))

    # Reset due to constraints (e.g., z position out of bounds)
    die = torch.where(self.root_pos[..., 2] < -2.0, torch.ones_like(self.reset_buf), die)
    die = torch.where(self.root_pos[..., 2] > 6.0, torch.ones_like(self.reset_buf), die)

    # Reset due to episode length
    self.reset_buf[:] = torch.where(self.progress_buf >= self._max_episode_length - 1, torch.ones_like(self.reset_buf), die)

#END
```